{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bexVn2CTaofr"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from LSTNet import LSTNetForClassification\n",
        "from utils import *\n",
        "import Optim\n",
        "from unimib_shar_adl_load_dataset import unimib_load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def namestr(obj, namespace):\n",
        "    return [name for name in namespace if namespace[name] is obj]\n",
        "\n",
        "def get_shapes(np_arr_list):\n",
        "    \"\"\"Returns text, each line is shape and dtype for numpy array in list\n",
        "       example: print(get_shapes([X_train, X_test, y_train, y_test]))\"\"\"\n",
        "    shapes = \"\"\n",
        "    for i in np_arr_list:\n",
        "        my_name = namestr(i,globals())\n",
        "        shapes += (my_name[0] + \" shape is \" + str(i.shape) \\\n",
        "            + \" data type is \" + str(i.dtype) + \"\\n\")\n",
        "    return shapes\n"
      ],
      "metadata": {
        "id": "03uqNAzpav7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new evaluation function for classification\n",
        "def evaluate_classification(data, X, Y, model, criterion, batch_size):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for X, Y in data.get_batches(X, Y, batch_size, False):\n",
        "        output = model(X)\n",
        "        loss = criterion(output, Y)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = output.max(1)\n",
        "        correct += predicted.eq(Y).sum().item()\n",
        "        total_samples += X.size(0)\n",
        "\n",
        "    accuracy = correct / total_samples\n",
        "    return total_loss, accuracy"
      ],
      "metadata": {
        "id": "V_cGMFwIa5pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description='PyTorch Time series classification')\n",
        "    parser.add_argument('--model', type=str, default='LSTNet', help='')\n",
        "    parser.add_argument('--hidCNN', type=int, default=100, help='number of CNN hidden units')\n",
        "    parser.add_argument('--hidRNN', type=int, default=100, help='number of RNN hidden units')\n",
        "    parser.add_argument('--num_classes', type=int, default=9, help='number of classes')  # Adjust the number of classes\n",
        "    parser.add_argument('--window', type=int, default=24 * 7, help='window size')  # Add 'window' parameter\n",
        "    parser.add_argument('--classification_loss', type=str, default='cross_entropy', help='classification loss function (e.g., cross_entropy)')\n",
        "    parser.add_argument('--cuda', action='store_true', default=False,\n",
        "                    help='Enable CUDA for GPU acceleration')\n",
        "\n",
        "    # Add other arguments as needed\n",
        "    args = parser.parse_args()\n",
        "    args.cuda = args.cuda and torch.cuda.is_available()  # Check if CUDA is available and the flag is set\n",
        "\n",
        "\n",
        "    if args.classification_loss == 'cross_entropy':\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    else:\n",
        "        raise NotImplementedError(\"Unsupported classification loss function\")\n"
      ],
      "metadata": {
        "id": "B6jtmBrma7ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  dataset = \"UniMiB SHAR\"\n",
        "    datasetfn = 'mobiact_adl_load_dataset.py'\n",
        "    full_filename = 'unimib_shar_adl_load_dataset.py'\n",
        "\n",
        "    #x_train, y_train, x_test, y_test = unimib_load_dataset(incl_val_group = False)\n",
        "    x_train, y_train, x_validate, y_validate, x_test, y_test = unimib_load_dataset(incl_val_group = True)\n",
        "    t_names = ['StandingUpFS','StandingUpFL','Walking','Running','GoingUpS','Jumping','GoingDownS','LyingDownFS','SittingDown']\n",
        "\n",
        "    train_ratio = 0.6\n",
        "    valid_ratio = 0.2\n",
        "    cuda = True\n",
        "    horizon = 12\n",
        "    window = 24\n",
        "    normalize = 2\n",
        "\n",
        "    data = Data_utility(x_train, train_ratio, valid_ratio, cuda, horizon, window, normalize)\n",
        "\n",
        "    print(get_shapes([x_train, y_train, x_validate, y_validate, x_test, y_test]))\n"
      ],
      "metadata": {
        "id": "fwoZL0lAa_9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Initialize and load your LSTNetForClassification model here\n",
        "    model = LSTNetForClassification(args, data )  # Modify this according to your model\n",
        "\n",
        "    # Train your model and perform validation\n",
        "    try:\n",
        "        print('begin training')\n",
        "        for epoch in range(1, args.epochs + 1):\n",
        "            # Training loop\n",
        "            train_loss = train(x_train, x_train.train[0], x_train.train[1], model, criterion, optim, args.batch_size)\n",
        "\n",
        "            # Validation loop\n",
        "            val_loss, val_accuracy = evaluate_classification(x_train, x_train.valid[0], x_train.valid[1], model, criterion, args.batch_size)\n",
        "\n",
        "            print('| end of epoch {:3d} | time: {:5.2f}s | train_loss {:5.4f} | valid_loss {:5.4f} | valid_accuracy {:5.4f}'.format(epoch, (time.time() - epoch_start_time), train_loss, val_loss, val_accuracy))\n",
        "\n",
        "        # Load the best saved model and evaluate on the test set\n",
        "        with open(args.save, 'rb') as f:\n",
        "            model = torch.load(f)\n",
        "        test_loss, test_accuracy = evaluate_classification(x_train, x_test.test[0], x_test.test[1], model, criterion, args.batch_size)\n",
        "        print(\"test_loss {:5.4f} | test_accuracy {:5.4f}\".format(test_loss, test_accuracy))\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('-' * 89)\n",
        "        print('Exiting from training early')"
      ],
      "metadata": {
        "id": "3jxI6D3-bG7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}